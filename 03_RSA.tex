% Presupposition CogSci 2016

In this section we introduce an extension to Rational Speech-Act (RSA) model
\cite{FrankGoodman2012:Predicting-Pragmatic-Reasoning-,GoodmanStuhlmuller2013:Knowledge-and-I} 
to account for the projection phenomenon of change-of-state verbs under negation,
 by formalizing the ideas introduced in the previous section. 
We will continue to use our working example of the conversation between Alice and Bob
 regarding John's smoking habit.

We consider the following relevant utterances: ``John smokes,'' 
 ``John smoked,'' ``John has always smoked,''
 ``John stopped smoking,'' ``John started smoking,'' 
 ``John has never smoked,'' and their negations. 
In addition, we introduce the null utterance ``'' (say nothing).
The prior probability of an utterance depends on the number of content words 
 (i.e., negation and auxiliaries are excluded) that it has.
The shorter an utterance, the higher its prior probability is, as defined in 
 (\ref{eq:utterance-prior}).

\begin{equation}
\Pr(u) \propto 2^{-\#\textrm{content-words}(u)}\label{eq:utterance-prior}
\end{equation}

The meaning/denotation of an utterance is standardly defined as the set of worlds 
 where the utterance is true.
We define a world $w$ as a pair.
Its first element is whether John smoked in the past 
 and its second element is whether John smokes now. 
This gives us a set of four possible worlds (the \emph{universe} 
 $U=\{(T, T), (T, F), (F, T), (F, F)\}$).
All positive utterances and their denotations are listed in Table~\ref{tab:pos-utt-denotations}.
In addition, we define that saying nothing is always true, and that the denotation 
 of the negation of an utterance $u$ is $U-\intp{$u$}$.
%``John stopped smoking'' is true iff 
% John smoked in the past and does not smoke now, i.e., $\intp{John stopped smoking}$
% $=\{\verb+(#t #f)+\}$, and we have 
%$\intp{John didn't stop smoking}= U - \{\verb+(#t #f)+\} = \{\verb+(#t #t)+,
% \verb+(#f #t)+, \verb+(#f #f)+\}$. 

\begin{table}
\centering
\begin{tabular}{cc}
$u$ &  $\intp{$u$}$  \\ \hline
``John smokes''  & $\{(T, T), (F, T)\}$ \\ 
``John smoked'' & $\{(T, T), (T, F)\}$ \\ 
``John has always smoked'' & $\{(T, T)\}$ \\
``John stopped smoking'' & $\{(T, F)\}$ \\
``John started smoking'' & $\{(F, T)\}$ \\
``John has never smoked'' & $\{(F, F)\}$ 
\end{tabular}
\caption{Positive utterances and their denotations \label{tab:pos-utt-denotations}}
\end{table}


A \emph{Question Under Discussion} (QUD) is a function $Q$ that takes a possible world as 
 its argument and returns the answer to the question in this world.
For example, QUD$_\textrm{now}$ is the question ``Does John smoke now?'' 
It takes a world and returns its second element, which answers whether 
 John smokes now. 
Another example is the maximal QUD$_\textrm{max}$, which is the identity function. 
Intuitively, QUD$_\textrm{max}$ is asking which is the current world.
It is maximal in the sense that knowing it's answer means knowing the answer to 
 any QUD.
 
The RSA model we propose to account for projective behavior has additional 
 components and assumptions to the standard version in the literature
 \cite{FrankGoodman2012:Predicting-Pragmatic-Reasoning-,GoodmanStuhlmuller2013:Knowledge-and-I,GoodmanLassiter2015-Chapter}.
To better illustrate why each of them is necessary and how they contribute to 
 the model's prediction, we will present the model incrementally. 
We will start with the standard RSA model, point out its problems, motivate 
 a modification, explain the problem it addresses, review the remaining issues, 
 motivate another modification, and so on, until we reach the final model.

\ 

\noindent\textbf{Standard RSA model}

In the standard RSA model (augmented with QUD as in \citeA{GoodmanLassiter2015-Chapter}), the literal listener, given an utterance and a QUD, 
 randomly samples a world that is consistent with the utterance, 
 and returns the value of the QUD in that world, as in (\ref{eq:literal-noCG}). 
In this paper we always assume that all worlds are equally likely \emph{a priori}, 
 i.e. $\Pr(w)=1/4$ for each $w$.

\begin{equation}
L_0(Q(w) \mid u, Q) = \Pr(Q(w) \mid w \in \intp{u}) \label{eq:literal-noCG}
\end{equation}
 
 \ndg{this notation isn't the best: the distribution over Q(w) isn't fully defined and the impact of literal meaning is better specified by a delta function.
 it's cleaner to handle the QUD in the speaker.i'd do it like: 
 $P_{L_0}(w \mid u) \propto \delta_{w\in \intp{u}}$ 
 and $P_{S}(u\mid w,Q) \propto P(u)\sum_{Q(w)=Q(w')}P_{L_0}(w' \mid u)$.
 i'm not going to make this change, since it affects a lot. y'all can if you want, or we can do it in the post-submit revision...}
 
\begin{table*}
\centering
\begin{tabular}{c|c|c|c|c}
         & Standard (no CG + QUD$_\text{max}$ ) & Uniform CS + QUD$_\text{max}$ & CG prior + QUD$_\text{max}$ & CG prior + QUD$_\text{now}$ \\ \hline 
literal  & $L_0(Q(w) \mid u, Q) = \Pr(Q(w) \mid w \in \intp{u})$ & 
\multicolumn{3}{c}{$L_0(Q(w) \mid u, C, Q) = \Pr(Q(w) \mid w \in \intp{u} \cap C)$} \\
speaker  & $S(u | w, Q) \propto \Pr(u) \cdot L_0(Q(w) \mid u, Q)^\alpha $ & \multicolumn{3}{c}{$S(u | w, C, Q) \propto \Pr(u) \cdot L_0(Q(w) \mid u, C, Q)^\alpha$} \\
listener & $L(w \mid u, Q) \propto \Pr(w) \cdot S(u \mid w, Q)$ & \multicolumn{3}{c}{$L(w, C \mid u, Q) \propto \Pr(w) \cdot \Pr(C) \cdot S(u \mid w, C, Q)$} \\
CG prior & -- & $\Pr(C) \propto 1$ & \multicolumn{2}{c}{$\Pr(C)=0.95\cdot\Pr(C=\cap\text{CG}_\text{Obs})+0.05\cdot 1/15$} \\
QUD      & $\text{QUD}_\text{max}(w)=w$ & $\text{QUD}_\text{max}(w)=w$ & $\text{QUD}_\text{max}(w)=w$ & $\text{QUD}_\text{now}((x,y))=y$\\
%QUD      & \multicolumn{3}{c}{$\text{QUD}_\text{max}(w)=w$} & $\text{QUD}_\text{now}((x,y))=y$\\
\hline
\end{tabular}
\caption{Specifications of four RSA models \label{tab:models}, with $\Pr(w)\propto1$ and $\Pr(u) \propto 2^{-\#\textrm{content-words}(u)}$ for all four models}
\end{table*} 
 
\begin{figure*}
 \centering
 \subfigure[No CG + QUD$_\text{max}$]{\label{fig:vanillaRSA}
 \includegraphics[scale=0.23]{figs/vanillaRSA.pdf}}
 \subfigure[Uniform CS + QUD$_\text{max}$]{\label{fig:RSA_uniformCG}
 \includegraphics[scale=0.23]{figs/uniformCG.pdf}}
 \subfigure[CG prior + QUD$_\text{max}$]{\label{fig:RSA_CGprior}
   \includegraphics[scale=0.23]{figs/CGprior.pdf}}
 \subfigure[CG prior + QUD$_\text{now}$]{\label{fig:RSA_QUDnow}
   \includegraphics[scale=0.23]{figs/QUDnow.pdf}}
 \caption{Pragmatic listener after hearing ``John did not stop smoking'' for each model, with $\alpha=6$ }
\end{figure*}

For example, if the relevant QUD is maximal (``QUD$_\textrm{max}$'', asking for a complete specification of the state of the world), the literal listener will rule out world
 $(T, F)$, and returns the remaining 3 worlds with equal probability.


Given the actual world and the QUD, the probability of 
 the speaker's utterance $u$ depends on two factors: the utterance prior 
 and the probability that the utterance will make the literal listener 
 return the correct answer to the QUD, as in (\ref{eq:speaker-noCG}).
 
\begin{equation}
S(u | w, Q) \propto \Pr(u) \cdot L_0(Q(w) \mid u, Q)^\alpha 
\label{eq:speaker-noCG}
\end{equation}

Here $\alpha$ is a rationality parameter controlling the extent to which 
 the speaker optimizes her utterance to induce the correct answer from the 
 literal listener. 
When $\alpha \rightarrow \infty$, the speaker will choose utterances that 
 strictly maximize the probability of inducing the right answer.
In this paper we set $\alpha=6$, but the qualitative predictions do not hinge on 
 this specific value.

The pragmatic listener, given the QUD, infers the actual world given the speaker's utterance, using Bayes' rule (\ref{eq:listener-noCG}).

\begin{equation}
L(w \mid u, Q) \propto \Pr(w) \cdot S(u \mid w, Q) \label{eq:listener-noCG}
\end{equation}

The standard RSA model is summarized in the first column of Table~\ref{tab:models},
 and the predicted pragmatic listener's distribution over worlds is shown in Figure~\ref{fig:vanillaRSA}.
As we can see, the standard RSA model predicts a uniform distribution over the
 three worlds that are consistent with the literal meaning of 
 ``John did not stop smoking''. It therefore fails to capture the projective content --- the inference that  
 John used to smoke.

The reason for this failure is that ``John did not stop smoking'' is equally
 under-informative in any of the three worlds compatible with its literal meaning.
For example, suppose the actual world is $(T, T)$, since the 
 literal listener will return this world with probability only $1/3$ after hearing ``John did not stop smoking,'' the speaker is unlikely to choose this utterance.
She is more likely to say ``John has always smoked'' instead, which will always
 induce the correct answer. 
The same holds for the other two worlds $(F, T)$ and $(F,
 F)$ and therefore the pragmatic listener in the standard RSA model will 
 infer that the three worlds are equally likely.
 
\ 

\noindent\textbf{RSA with common ground}

\begin{figure*}
 \centering
 \subfigure[Uniform CS + QUD$_\text{max}$]{\label{fig:joint-uniform}
  \includegraphics[scale=0.48]{figs/joint_uniformCG_QUDmax.pdf}} 
  \hspace{5pt}
 \subfigure[CG prior + QUD$_\text{max}$]{\label{fig:joint-CGprior}
 \includegraphics[scale=0.48]{figs/joint_CGprior_QUDmax.pdf}} 
% \hspace{5pt}
%  \subfigure[CG prior + QUD$_\text{now}$]{\label{fig:joint-QUDnow}
%  \includegraphics[scale=0.26]{figs/alpha6CGprior_QUDnow.png}}%alpha6cost1eqllhcg
 \caption{Pragmatic listener after hearing ``John did not stop smoking,'' with $\alpha=6$\label{fig:prior}}
\end{figure*}

We have seen that one important reason that the standard RSA model fails to 
 capture the projective content of ``John stopped smoking'' is that its literal
 meaning is under-informative when considered in the entire universe $U$.
However, as discussed before, there can be information taken for granted by the
 speaker and the listener, i.e., the common ground, 
and an utterance under-informative when considered in the entire universe $U$ may 
 nevertheless be informative when evaluated in the common ground.
To formalize this observation, we now add common ground to the RSA model.

We first define a related notion. 
A \emph{context set} \cite{Stalnaker1974:Pragmatic-Presuppositions} $C$ is a non-empty subset of the universe.
Since we have 4 possible worlds, there are $2^4-1=15$ different context sets.
These context sets are intuitively named. 
For example, \verb=+past= is the context set
 that contains $(T, T)$ and $(T, F)$,
\verb=+past+now= contains only $(T, T)$,
$\sim$\verb=+past+now= contains all the worlds except $(T, T)$, 
and \verb=change= is the context set that contains $(T, F)$ 
 and $(F, T)$.

A literal listener, given an utterance, the current context set and QUD, 
 randomly samples a world that is consistent with both the utterance and 
 the context set, and returns the value of the QUD in that world, as in  
 (\ref{eq:literal-CG}).

\begin{equation}
L_0(Q(w) \mid u, C, Q) = \Pr(Q(w) \mid w \in \intp{u} \cap C) \label{eq:literal-CG}
\end{equation}

For example, given context set \verb=+past= and QUD$_\text{max}$, 
 after hearing ``John stopped smoking,'' the literal listener will rule out 
 $(T, F)$ because of the utterance's literal meaning, and 
 $(F, T)$ and $(F, F)$ because 
 they are incompatible with the context set.
Therefore he will always return $(T, T)$.
We can see from this example that an utterance that is under-informative 
 when the entire universe is considered can be informative in some other 
 context sets.

The new speaker model is almost the same as (\ref{eq:speaker-noCG}), except that 
 it is relativized to the current context set, as in (\ref{eq:speaker-CG}).
 
\begin{equation}
S(u | w, C, Q) \propto \Pr(u) \cdot L_0(Q(w) \mid u, C, Q)^\alpha \label{eq:speaker-CG}
\end{equation}
 
Finally, given an utterance and the QUD, the pragmatic listener now jointly infers 
 the real world and the context set the speaker assumes when she produces the utterance. 

\begin{equation}
L(w, C \mid u, Q) \propto \Pr(w) \cdot \Pr(C) \cdot S(u \mid w, C, Q)
\end{equation}

In order for the model to work, we need to specify a prior distribution $\Pr(C)$ 
 over context sets.
We consider two possibilities. 
First, we consider a uniform distribution over all context sets, i.e., 
 $\Pr(C)\propto 1$.
Assuming the maximal QUD, the model is summarized in the second column of 
 Table~\ref{tab:models} and the pragmatic listener's marginal distribution over 
 worlds is shown in Figure~\ref{fig:RSA_uniformCG}.
We can see that this model predicts that $(F, T)$ is slightly 
 less likely than $(T, T)$ and $(F, F)$, 
 and $(T, T)$ has the same probability as $(F, F)$. 
This does not capture projection.


% explanation of why a uniform prior is undesirable
%
%
%Clearly this model does not capture projective phenomena, either. 
%But let us take a closer look at the model's prediction to see what the 
% problem might be. 
%Instead of only looking at the marginal distribution over worlds, we plot the joint
% distribution of world and common ground in Figure~\ref{fig:joint-uniformCG}.
%
%First, we see that the world $(T, T)$ with common ground 
% \verb=+past= is one of the two most likely outcomes. 
%This outcome means that John always smokes and that the speaker takes for 
% granted that John smoked in the past.
%This is exactly the expected projective behavior and therefore the model 
% seems to be on the right track by predicting it to be one of the most likely outcomes. 
%
%Intuitively, this outcome is (one of) the most likely because, as noted before,
% the common ground \verb=+past= makes the utterance ``John did not stop smoking'' maximally informative. 
%As a result, the speaker is more likely to choose this utterance when the
% common ground is \verb=+past= than some other common ground in which the utterance
% is relatively uninformative (e.g., the universe).
%Therefore, the pragmatic listener will infer that \verb=+past= is a likely common
% ground that the speaker assumes.
% 
%However, this cannot be the full story to account for projection, 
% because we can see from Figure~\ref{fig:joint-uniformCG} that 
% the world $(F, F)$ with common ground \verb=-now= is the other most likely outcome, and the world $(F, T)$ with common ground
% \verb=change= is the next most likely outcome.
%The former outcome means that John never smokes and that the speaker takes for
% granted that John does not smoke now.
%The latter outcome means that John started smoking and that the speaker takes for granted that there is a change regarding John's smoking habit.
%The reason why these two outcomes are likely is exactly the same as before: the 
% utterance ``John did not stop smoking'' is also maximally informative in these common grounds. 
%For example, when the common ground is \verb=-now=, i.e., the actual world is 
% either $(T, F)$ or $(F, F)$, the literal listener 
% will rule out $(T, F)$ after hearing ``John did not stop smoking''
% and therefore will always return $(F, F)$.
%
% 
%
%Therefore, although we have made some progress in capturing projection by
% adding a common ground component to the RSA model and reasoning about the 
% informativity of an utterance in a common ground, the current model 
% overgenerates possible projection patterns and predicts that the pragmatic listener thinks that they are roughly equally likely.
%This contradicts the empirical fact that people have a strong preference for only
% one of the projective patterns, and hence the model needs further revision 
% in order to explain why only $(T, T)$ with common ground 
%  \verb=+past= is preferred.
%
%
%
%Below, we will make two modifications. The first accounts for why 
% $(F, T)$ with common ground \verb=change= is dispreferred
% and the second for $(F, F)$ with common ground \verb=-now=.
 

%\noindent\textbf{Common ground prior}

The second possibility makes use of the notion of a \emph{common ground} (CG) 
 in the pragmatic approach to derive a prior over context sets
 \cite{Stalnaker1974:Pragmatic-Presuppositions}.
As previously discussed, intuitively a common ground represents all pieces of
 information taken for granted by the speaker and the listener.
Technically, a common ground is a set of propositions (a proposition is a set of
  worlds) that are taken for granted and the context set is the intersection of all the propositions in the common ground.
In our example scenario, the relevant information that Alice (the speaker) has 
 and can take for granted is typically the results of her observations about John's smoking status in the past and now.
Formally, we assume that there are two observations, about John's past and current
 smoking status, respectively. 
The result of each observation is independently likely to be in the common ground
 with probability $p$ (in this paper we set $p=40\%$, assuming that people 
 generally tend not to take information for granted).
The context set is generally ($95\%$) the intersection of such a common ground
 consisting of (some or no) observations,
 but very occasionally ($5\%$) it is uniformly chosen from all 15 possible context 
 sets to gloss over other ways to form a common ground.
In other words, the prior of a context set $C$ is defined in (\ref{eq:CGprior})

\begin{equation}
\Pr(C)=0.95\cdot\Pr(C=\cap\text{CG}_\text{Obs})+0.05\cdot 1/15 \label{eq:CGprior}
\end{equation}

Using the above notion of a common ground to derive the prior over context sets
 (summarized in the third column of Table~\ref{tab:models}), the pragmatic
 listener's marginal distribution over worlds is shown in Figure~\ref{fig:RSA_CGprior}.
We can see that this model predicts that $(F, T)$ is very unlikely,
 and $(T, T)$ has the same probability as $(F, F)$. 
Although this still does not capture projection because $(T, T)$ is predicted to be
 as likely as $(F, F)$, the model correctly predicts that $(F, T)$ is unlikely. 
Therefore we have made some progress.

To understand how a prior derived from the notion of a common ground 
 (henceforth CG prior) improves the model and what the remaining problem is, 
 we plot the pragmatic listener's joint distribution of world and context set in
 Figure~\ref{fig:prior}. 

With a uniform prior, the pragmatic listener has 3 most likely outcomes: 
 world $(T, T)$ with context set \verb=+past=, world $(F, F)$ with context set \verb=-now=, and world $(F, T)$ with context set \verb=change= (this last outcome
 is slightly less likely than the first two), as shown in Figure~\ref{fig:joint-uniform}.
This is why the marginal distribution over worlds is almost uniform over 
 $(T, T)$, $(F, F)$, and $(F, T)$.
In contrast, with a CG prior, while world $(T, T)$ with context set \verb=+past=
 and world $(F, F)$ with context set \verb=-now= are still the most likely outcomes,
 world $(F, T)$ with context set \verb=change= is no longer a likely outcome, 
 as shown in Figure~\ref{fig:joint-CGprior}.
World $(F, T)$ with context set \verb=change= is now dispreferred because 
 its context set \verb=change= has a very low prior since it is not the result 
 of taking observations about the past or now for granted.
This is why the world $(F, T)$ is no longer likely in the marginal distribution
 over worlds.

We acknowledge that the above CG prior is certainly over-simplified, 
 but the qualitative prediction really only depends on the 
 assumption that not all common sets are equally likely \emph{a priori}, and 
 in particular \verb=change= is a fairly unusual context set and 
 should be assigned a low prior probability.
This assumption seems intuitively plausible, and as long as it is satisfied, 
 there could be many alternative ways to motivate a more realistic prior over 
 context sets without affecting the model's crucial prediction.
 
On the other hand, we can see that world $(F, F)$ with common ground \verb=-now= 
 is still one of the most likely outcomes in Figure~\ref{fig:joint-CGprior}, and
 hence the marginal probability of $(F, F)$ is the same as $(T, T)$ in Figure~\ref{fig:RSA_CGprior}.
This is not desirable, but is totally expected from the model: 
 the prior for context set \verb=-now= is the same as for context set \verb=+past=. 
Therefore, to fully capture projective behavior, we need to further
 explain why $(F, F)$ with context set \verb=-now= is dispreferred.


\ 

\noindent\textbf{Non-maximal QUDs}

\begin{figure}
 \includegraphics[scale=0.48]{figs/joint_CGprior_QUDnow.pdf}
 \caption{Pragmatic listener after hearing ``John did not stop smoking,'' with $\alpha=6$, CG prior + QUD$_\text{now}$\label{fig:joint-QUDnow}}
\end{figure}

So far, we have been assuming that the QUD is maximal, i.e., the utterance 
 ``John did not stop smoking'' is chosen to address the question of
 whether John smoked in the past and whether John smokes now.
For this QUD, the RSA model with common ground prior predicts a tie between 
 $(T, T)$ with context set \verb=+past= and
 $(F, F)$ with context set \verb=-now=.
 
The maximal QUD is commonly assumed in applications of RSA models, but 
 in this case there are good reasons to consider non-maximal QUDs.
Empirically, as noted in the beginning, projection is sensitive to the QUD.
Theoretically, there has been a lot of discussion in the previous literature
 \cite{Beaver2010:Have-You-Noticed, SimonsEtAl2001:What-Projects-and-Why} on the relation between at-issueness and projection, where at-issueness is defined 
 relative to a QUD not necessarily maximal.
 
In our working example, Bob explicitly asked about whether John smokes, 
 which means that the QUD is QUD$_\textrm{now}$.
When we use the previous RSA model with the common ground prior, but  
 replace QUD$_\textrm{max}$ with QUD$_\textrm{now}$ (summarized in the 
 last column of Table~\ref{tab:models}), the pragmatic listener's marginal probability over worlds is shown in Figure~\ref{fig:RSA_QUDnow} and the joint
 distribution of world and context set is in Figure~\ref{fig:joint-QUDnow}.
We can see from Figure~\ref{fig:joint-QUDnow} that $(T, T)$ with context set
 \verb=+past= is 
 the only most likely outcome, and the world $(T, T)$ is the 
 only most likely world (and its probability increases with a higher $\alpha$).
This is exactly the projection pattern we aim to capture.

To understand why we obtain this result, we note that 
 when the QUD is QUD$_\textrm{now}$, $(F, F)$ with context set
 \verb=-now= is dispreferred because the context set \verb=-now= already entails 
 the answer to the QUD. 
That is, it is already known from the context set \verb=-now= that John does not 
 smoke now.
This means that the speaker would be maximally informative even if he says nothing.
As a result, the speaker would be unlikely to say ``John did not stop smoking'' 
 when the context set is \verb=-now=, and the pragmatic listener could therefore
 infer that the context set \verb=-now= is unlikely, which means that 
 $(T, T)$ with context set \verb=+past= is the only winner.

%The model's prediction changes when we use a different QUD. 
%When the QUD is whether John smoked in the past, the model predicts that 
% the listener will infer that world $(F, F)$ with common
% ground \verb=-now= is most likely, as shown in Fig.~\ref{fig:joint-QUDpast}.
%This means that John never smokes and the speaker takes for granted that 
% John does not smoke now.
%This type of projection might be accessible in a scenario where there
% is a rumor about John being a heavy smoker in the past, and the speaker uses 
% ``John did not stop smoking'' to jokingly refute it.

Therefore the current model correctly predicts the projective behavior for 
 ``John did not stop smoking'' in the example scenario, where the QUD is explicitly
 given by Bob's question. 
Assuming that people generally care about information concerning now rather than 
 the past, i.e., the default or most salient QUD is QUD$_\text{now}$,
the model predicts that the preferred projective content of 
 ``John did not stop smoking'' without explicit QUD is that 
 John smoked in the past, which is also correct.

This completes the RSA model. In the next section we will further illustrate its predictions about the interaction between projection and QUD. 

