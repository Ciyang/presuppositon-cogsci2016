% Presupposition CogSci 2016

In this section we introduce an extension to Rational Speech-Act (RSA) model
\cite{FrankGoodman2012:Predicting-Pragmatic-Reasoning-,GoodmanStuhlmuller2013:Knowledge-and-I} 
to account for the projection phenomenon of change-of-state verbs under negation,
 by formalizing the ideas introduced in the previous section. 
We will continue to use our working example of the conversation between Alice and Bob
 regarding John's smoking habit.

We consider the following relevant utterances: ``John smokes,'' 
 ``John smoked,'' ``John always smokes,''
 ``John stopped smoking,'' ``John started smoking,'' 
 ``John never smokes,'' and their negations. 
In addition, we introduce the null utterance ``'' (say nothing).
The prior probability of an utterance depends on the number of content words 
 (i.e., negation and auxiliaries are excluded) that it has.
The shorter an utterance, the higher its prior probability is, as defined in 
 (\ref{eq:utterance-prior}).

\begin{equation}
\Pr(u) \propto 2^{-\#\textrm{content-words}(u)}\label{eq:utterance-prior}
\end{equation}

The meaning/denotation of an utterance is standardly defined as the set of worlds 
 where the utterance is true.
We define a world $w$ as a pair.
Its first element is whether John smoked in the past 
 and its second element is whether John smokes now. 
This gives us a set of four possible worlds (the \emph{universe} 
 $U=\{$(\verb+#t+, \verb+#t+), (\verb+#t+, \verb+#f+), (\verb+#f+, \verb+#t+), (\verb+#f+, \verb+#f+)$\}$).
All positive utterances and their denotations are listed in Table~\ref{tab:pos-utt-denotations}.
In addition, we define that saying nothing is always true, and that the denotation 
 of the negation of an utterance $u$ is $U-\intp{$u$}$.
%``John stopped smoking'' is true iff 
% John smoked in the past and does not smoke now, i.e., $\intp{John stopped smoking}$
% $=\{\verb+(#t #f)+\}$, and we have 
%$\intp{John didn't stop smoking}= U - \{\verb+(#t #f)+\} = \{\verb+(#t #t)+,
% \verb+(#f #t)+, \verb+(#f #f)+\}$. 

\begin{table}
\centering
\begin{tabular}{cc}
$u$ &  $\intp{$u$}$ \\ \hline
``John smokes''  & $\{(\verb+#t+, \verb+#t+), (\verb+#f+, \verb+#t+)\}$ \\ 
``John smoked'' & $\{(\verb+#t+, \verb+#t+), (\verb+#t+, \verb+#f+)\}$ \\ 
``John always smokes'' & $\{(\verb+#t+, \verb+#t+)\}$ \\
``John stopped smoking'' & $\{(\verb+#t+, \verb+#f+)\}$ \\
``John started smoking'' & $\{(\verb+#f+, \verb+#t+)\}$ \\
``John never smokes'' & $\{(\verb+#f+, \verb+#f+)\}$ 
\end{tabular}
\caption{Positive utterances and their denotations \label{tab:pos-utt-denotations}}
\end{table}


A \emph{Question Under Discussion} (QUD) \cite{Roberts2012:Information-Structure} is a function $Q$ that takes a possible world as 
 its argument and returns the answer to the question in this world.
For example, QUD$_\textrm{now}$ is the question ``Does John smoke now?'' which takes a world and returns its second element.
It answers whether John smokes now. 
Another example is the maximal QUD$_\textrm{max}$, which is the identity function. 
Intuitively, QUD$_\textrm{max}$ is asking which is the current world.
It is maximal in the sense that knowing its answer means knowing the answer to 
 any QUD.
 
The RSA model we propose to account for projective behavior has additional 
 components and assumptions to the standard version in the literature
 \cite{FrankGoodman2012:Predicting-Pragmatic-Reasoning-,GoodmanStuhlmuller2013:Knowledge-and-I}.
To better illustrate why each of them is necessary and how they contribute to 
 the model's prediction, we will present the model incrementally. 
We will start with the standard RSA model, point out its problems, motivate 
 a modification, explain the problem it addresses, review the remaining issues, 
 motivate another modification, and so on, until we reach the final model.

\ 

\noindent\textbf{Standard RSA model}

In the standard RSA model, the literal listener, given an utterance and a QUD, 
 randomly samples a world that is consistent with the utterance, 
 and returns the value of the QUD in that world, as in (\ref{eq:literal-noCG}). 
In this paper we always assume that all worlds are equally likely \emph{a priori}, 
 i.e. $\Pr(w)=1/4$ for each $w$.

\begin{equation}
L_0(Q(w) \mid u, Q) = \Pr(Q(w) \mid w \in \intp{u}) \label{eq:literal-noCG}
\end{equation}
 
\begin{table*}
\centering
\begin{tabular}{c|c|c|c|c}
         & Standard (no CG + QUD$_\text{max}$ ) & Uniform CG + QUD$_\text{max}$ & CG prior + QUD$_\text{max}$ & CG prior + QUD$_\text{now}$ \\ \hline 
literal  & $L_0(Q(w) \mid u, Q) = \Pr(Q(w) \mid w \in \intp{u})$ & 
\multicolumn{3}{c}{$L_0(Q(w) \mid u, C, Q) = \Pr(Q(w) \mid w \in \intp{u} \cap C)$} \\
speaker  & $S(u | w, Q) \propto \Pr(u) \cdot L_0(Q(w) \mid u, Q)^\alpha $ & \multicolumn{3}{c}{$S(u | w, C, Q) \propto \Pr(u) \cdot L_0(Q(w) \mid u, C, Q)^\alpha$} \\
listener & $L(w \mid u, Q) \propto \Pr(w) \cdot S(u \mid w, Q)$ & \multicolumn{3}{c}{$L(w, C \mid u, Q) \propto \Pr(w) \cdot \Pr(C) \cdot S(u \mid w, C, Q)$} \\
CG prior & -- & $\Pr(C) \propto 1$ & \multicolumn{2}{c}{$\Pr(C)=0.95\cdot\Pr(\text{Obs}=C)+0.05\cdot 1/15$} \\
QUD      & $\text{QUD}_\text{max}(w)=w$ & $\text{QUD}_\text{max}(w)=w$ & $\text{QUD}_\text{max}(w)=w$ & $\text{QUD}_\text{now}((x,y))=y$\\
%QUD      & \multicolumn{3}{c}{$\text{QUD}_\text{max}(w)=w$} & $\text{QUD}_\text{now}((x,y))=y$\\
\hline
\end{tabular}
\caption{Specifications of four RSA models \label{tab:models}, with $\Pr(w)\propto1$ and $\Pr(u) \propto 2^{-\#\textrm{content-words}(u)}$ for all four models}
\end{table*} 
 
\begin{figure*}
 \centering
 \subfigure[No CG + QUD$_\text{max}$]{\label{fig:vanillaRSA}
 \includegraphics[scale=0.23]{figs/vanillaRSA.pdf}}
 \subfigure[Uniform CS + QUD$_\text{max}$]{\label{fig:RSA_uniformCG}
 \includegraphics[scale=0.23]{figs/uniformCG.pdf}}
 \subfigure[CG prior + QUD$_\text{max}$]{\label{fig:RSA_CGprior}
   \includegraphics[scale=0.23]{figs/CGprior.pdf}}
 \subfigure[CG prior + QUD$_\text{now}$]{\label{fig:RSA_QUDnow}
   \includegraphics[scale=0.23]{figs/QUDnow.pdf}}
 \caption{Pragmatic listener after hearing ``John did not stop smoking'' for each model, with $\alpha=6$ }
\end{figure*}


For example, if the relevant QUD is maximal (``QUD$_\textrm{max}$'', asking for a complete specification of the state of the world), a literal listener will respond to ``John did not stop smoking'' by ruling out world (\verb+#t+, \verb+#f+) and normalizing.


Given the actual world and the QUD, the probability of 
 the speaker's utterance $u$ depends on two factors: the utterance prior 
 and the probability that the utterance will make the literal listener 
 return the correct answer to the QUD, as in (\ref{eq:speaker-noCG}).
 
\begin{equation}
S(u | w, Q) \propto \Pr(u) \cdot L_0(Q(w) \mid u, Q)^\alpha 
\label{eq:speaker-noCG}
\end{equation}

Here $\alpha$ is a rationality parameter controlling the extent to which 
 the speaker optimizes her utterance to induce the correct answer from the 
 literal listener. 
When $\alpha \rightarrow \infty$, the speaker will choose utterances that 
 strictly maximize the probability of inducing the right answer.
In this paper we set $\alpha=6$, but the qualitative predictions do not hinge on 
 this specific value.

The pragmatic listener, given the QUD, infers the actual world given the speaker's utterance, using Bayes' rule (\ref{eq:listener-noCG}).

\begin{equation}
L(w \mid u, Q) \propto \Pr(w) \cdot S(u \mid w, Q) \label{eq:listener-noCG}
\end{equation}

The standard RSA model is summarized in the first column of Table~\ref{tab:models},
 and the predicted pragmatic listener's distribution over worlds is shown in Figure~\ref{fig:vanillaRSA}.
As we can see, the standard RSA model predicts a uniform distribution over the
 three worlds that are consistent with the literal meaning of 
 ``John did not stop smoking''. It therefore fails to capture the projective content --- the inference that  
 John used to smoke.

The reason for this failure is that ``John did not stop smoking'' is equally
 underinformative in any of the three worlds compatible with its literal meaning.
For example, suppose the actual world is $(\verb+#t+, \verb+#t+)$, since the 
 literal listener will return this world with probability only $1/3$ after hearing ``John did not stop smoking,'' the speaker is unlikely to choose this utterance.
She is more likely to say ``John always smokes'' instead, which will always induce 
 the correct answer. 
The same holds for the other two worlds $(\verb+#f+, \verb+#t+)$ and $(\verb+#f+,
 \verb+#f+)$ and therefore the pragmatic listener in the standard RSA model will 
 infer that the three worlds are equally likely.
 
\ 

\noindent\textbf{RSA with common ground}

\begin{figure*}
 \centering
 \subfigure[Uniform CS + QUD$_\text{max}$]{\label{fig:joint-uniform}
  \includegraphics[scale=0.26]{figs/alpha6uniformCG_QUDmax.png}} 
  \hspace{5pt}
 \subfigure[CG prior + QUD$_\text{max}$]{\label{fig:joint-CGprior}
 \includegraphics[scale=0.26]{figs/alpha6CGprior_QUDmax.png}} 
% \hspace{5pt}
%  \subfigure[CG prior + QUD$_\text{now}$]{\label{fig:joint-QUDnow}
%  \includegraphics[scale=0.26]{figs/alpha6CGprior_QUDnow.png}}%alpha6cost1eqllhcg
 \caption{Pragmatic listener after hearing ``John did not stop smoking,'' with $\alpha=6$ }
\end{figure*}

We have seen that one important reason that the standard RSA model fails to 
 capture the projective content of ``John stopped smoking'' is that its literal
 meaning is underinformative when the entire universe $U$ is considered.
However, as discussed before, there can be information taken for granted by the
 speaker and the listener, i.e., the common ground. 
And an utterance underinformative when considered in the entire universe $U$ may 
 nevertheless be informative when evaluated in the common ground.
To make use of this observation, we now add common ground to the RSA model.

We first define a related notion. 
A \emph{context set} \cite{Stalnaker1974:Pragmatic-Presuppositions} $C$ is a non-empty subset of the universe.
Since we have 4 possible worlds, there are $2^4-1=15$ different context sets.
These context sets are intuitively named. 
For example, \verb=+past= is the context set
 that contains $(\verb+#t+, \verb+#t+)$ and $(\verb+#t+, \verb+#f+)$,
\verb=+past+now= contains only $(\verb+#t+, \verb+#t+)$,
\verb=~+past+now= contains all the worlds except $(\verb+#t+, \verb+#t+)$, 
\verb=change= is the context set that contains $(\verb+#t+, \verb+#f+)$ 
 and $(\verb+#f+, \verb+#t+)$.

A literal listener, given an utterance, the current context set and QUD, 
 randomly samples a world that is consistent with both the utterance and 
 the context set, and returns the value of the QUD in that world, as in  
 (\ref{eq:literal-CG}).

\begin{equation}
L_0(Q(w) \mid u, C, Q) = \Pr(Q(w) \mid w \in \intp{u} \cap C) \label{eq:literal-CG}
\end{equation}

For example, given context set \verb=+past= and QUD$_\text{max}$, 
 after hearing ``John stopped smoking,'' the literal listener will rule out 
 $(\verb+#t+, \verb+#f+)$ because of the utterance's literal meaning, and 
 $(\verb+#f+, \verb+#t+)$ and $(\verb+#f+, \verb+#f+)$ because 
 they are incompatible with the context set.
Therefore he will always return $(\verb+#t+, \verb+#t+)$.
We can see from this example that an utterance that is underinformative 
 when the entire universe is considered can be maximally informative in certain 
 context sets.

The new speaker model is almost the same as (\ref{eq:speaker-noCG}), except that 
 it is relativized to the current context set, as in (\ref{eq:speaker-CG}).
 
\begin{equation}
S(u | w, C, Q) \propto \Pr(u) \cdot L_0(Q(w) \mid u, C, Q)^\alpha \label{eq:speaker-CG}
\end{equation}
 
Finally, given an utterance and the QUD, the pragmatic listener now jointly infers 
 the real world and the context set the speaker assumes when she produces the utterance. 

\begin{equation}
L(w, C \mid u, Q) \propto \Pr(w) \cdot \Pr(C) \cdot S(u \mid w, C, Q)
\end{equation}

In order for the model to work, we need to specify a prior distribution $\Pr(C)$ 
 over context sets.
We consider two possibilities. 
First, we consider a uniform distribution over all context sets, i.e., 
 $\Pr(C)\propto 1$.
Assuming the maximal QUD, the model is summarized in the second column of 
 Table~\ref{tab:models} and the pragmatic listener's marginal distribution over 
 worlds is shown in Figure~\ref{fig:RSA_uniformCG}.
We can see that this model predicts that $(\verb+#f+, \verb+#t+)$ is slightly 
 less likely than $(\verb+#t+, \verb+#t+)$ and $(\verb+#f+, \verb+#f+)$, 
 and $(\verb+#t+, \verb+#t+)$ has the same probability as $(\verb+#f+, \verb+#f+)$.


% explanation of why a uniform prior is undesirable
%
%
%Clearly this model does not capture projective phenomena, either. 
%But let us take a closer look at the model's prediction to see what the 
% problem might be. 
%Instead of only looking at the marginal distribution over worlds, we plot the joint
% distribution of world and common ground in Figure~\ref{fig:joint-uniformCG}.
%
%First, we see that the world $(\verb+#t+, \verb+#t+)$ with common ground 
% \verb=+past= is one of the two most likely outcomes. 
%This outcome means that John always smokes and that the speaker takes for 
% granted that John smoked in the past.
%This is exactly the expected projective behavior and therefore the model 
% seems to be on the right track by predicting it to be one of the most likely outcomes. 
%
%Intuitively, this outcome is (one of) the most likely because, as noted before,
% the common ground \verb=+past= makes the utterance ``John did not stop smoking'' maximally informative. 
%As a result, the speaker is more likely to choose this utterance when the
% common ground is \verb=+past= than some other common ground in which the utterance
% is relatively uninformative (e.g., the universe).
%Therefore, the pragmatic listener will infer that \verb=+past= is a likely common
% ground that the speaker assumes.
% 
%However, this cannot be the full story to account for projection, 
% because we can see from Figure~\ref{fig:joint-uniformCG} that 
% the world $(\verb+#f+, \verb+#f+)$ with common ground \verb=-now= is the other most likely outcome, and the world $(\verb+#f+, \verb+#t+)$ with common ground
% \verb=change= is the next most likely outcome.
%The former outcome means that John never smokes and that the speaker takes for
% granted that John does not smoke now.
%The latter outcome means that John started smoking and that the speaker takes for granted that there is a change regarding John's smoking habit.
%The reason why these two outcomes are likely is exactly the same as before: the 
% utterance ``John did not stop smoking'' is also maximally informative in these common grounds. 
%For example, when the common ground is \verb=-now=, i.e., the actual world is 
% either $(\verb+#t+, \verb+#f+)$ or $(\verb+#f+, \verb+#f+)$, the literal listener 
% will rule out $(\verb+#t+, \verb+#f+)$ after hearing ``John did not stop smoking''
% and therefore will always return $(\verb+#f+, \verb+#f+)$.
%
% 
%
%Therefore, although we have made some progress in capturing projection by
% adding a common ground component to the RSA model and reasoning about the 
% informativity of an utterance in a common ground, the current model 
% overgenerates possible projection patterns and predicts that the pragmatic listener thinks that they are roughly equally likely.
%This contradicts the empirical fact that people have a strong preference for only
% one of the projective patterns, and hence the model needs further revision 
% in order to explain why only $(\verb+#t+, \verb+#t+)$ with common ground 
%  \verb=+past= is preferred.
%
%
%
%Below, we will make two modifications. The first accounts for why 
% $(\verb+#f+, \verb+#t+)$ with common ground \verb=change= is dispreferred
% and the second for $(\verb+#f+, \verb+#f+)$ with common ground \verb=-now=.
 

%\noindent\textbf{Common ground prior}

The second possibility makes use of the notion of a \emph{common ground} (CG) 
 in the pragmatic approach to derive a prior over context sets
 \cite{Stalnaker1974:Pragmatic-Presuppositions}.
As previously discussed, intuitively a common ground represents the information 
 taken for granted by the speaker and the listener.
Technically, a common ground is a set of propositions (propositions are sets of
  worlds) and the context set is the intersection of all the propositions in the common ground.
In our example scenario, the relevant information that Alice (the speaker) has 
 and can take for granted is her knowledge about John's smoking status in the 
 past or now, most typically obtained from her direct observation.
Therefore, we assume that there are two observations, about John's past and current
 smoking status, respectively. 
The result of each observation is independently $40\%$ likely to be taken for
 granted ($40\%$ reflects the assumption that people are more likely not to take these results for granted) and enter the common ground.
The common ground generally ($95\%$) consists of only observation results,
 but very occasionally ($5\%$) it contains random information to gloss over
 non-typical information common ground.
In other words, the prior of a context set $C$ is defined in (\ref{eq:CGprior})

\begin{equation}
\Pr(C) = \Pr(C=\cap\text{CG}) \label{eq:CGprior}
\end{equation}



Using the RSA model with common ground introduced before, 
 but with the above common ground prior instead of a uniform distribution 
 (summarized in the third column of Table~\ref{tab:models}), the pragmatic
 listener's marginal distribution over worlds is shown in Figure~\ref{fig:RSA_CGprior} and the joint distribution of world and
  common ground is in Figure~\ref{fig:joint-CGprior}. 
We can see that the world $(\verb+#f+, \verb+#t+)$ with common ground
 $(\verb+#f+, \verb+#t+)$ with common ground \verb=change= is no longer a likely outcome,
 and the marginal probability of world $(\verb+#f+, \verb+#t+)$ greatly decreases.
This means that the new model correctly predicts that $(\verb+#f+, \verb+#t+)$ with
 common ground \verb=change= is dispreferred, and this is achieved due to the low prior probability of the common ground \verb=change=.

We note that the above derivation of the common ground prior is certainly
 over-simplified, but the qualitative prediction really only depends on the 
 assumption that not all common grounds are equally likely \emph{a priori}, and 
 in particular \verb=change= is a fairly unusual common ground and 
 should be assigned a low prior probability.
This assumption seems intuitively plausible, and as long as it is satisfied, 
 there could be many alternative ways to motivate a different common ground prior
 without affecting the model's crucial prediction.
 
However, we can see that the world $(\verb+#f+, \verb+#f+)$ 
 with common ground \verb=-now= 
 is still one of the most likely outcomes in Figure~\ref{fig:joint-CGprior}, and the marginal
 probability of $(\verb+#f+, \verb+#f+)$ is the same as $(\verb+#t+, \verb+#t+)$ in Figure~\ref{fig:RSA_CGprior}.
This is not desirable, but is totally expected from the model: the common ground prior for \verb=-now= is the same as 
 \verb=+past=.
Therefore, we need another way to explain why $(\verb+#f+, \verb+#f+)$ 
 with common ground \verb=-now= is empirically dispreferred.


\ 

\noindent\textbf{Non-maximal QUDs}

\begin{figure}
 \includegraphics[scale=0.26]{figs/alpha6CGprior_QUDnow.png}%alpha6cost1eqllhcg
 \caption{Pragmatic listener after hearing ``John did not stop smoking,'' with $\alpha=6$, CG prior + QUD$_\text{now}$\label{fig:joint-QUDnow}}
\end{figure}

So far, we have been assuming that the QUD is maximal, i.e., the utterance 
 ``John did not stop smoking'' is chosen to address the question of
 whether John smoked in the past and whether John smokes now.
For this QUD, the RSA model with common ground prior predicts a tie between 
 $(\verb+#t+, \verb+#t+)$ with common ground \verb=+past= and
 $(\verb+#f+, \verb+#f+)$ with common ground \verb=-now=.
The maximal QUD is commonly assumed in applications of RSA models, but 
 in this case there are good reasons to consider non-maximal QUDs.
Empirically, as noted in the beginning, projection is sensitive to the QUD.
Theoretically, there has been a lot of discussion in the previous literature
 \cite{Beaver2010:Have-You-Noticed, SimonsEtAl2001:What-Projects-and-Why} on the relation between at-issueness and projection, where at-issueness is defined 
 relative to a QUD not necessarily maximal.
 
In our working example, Bob explicitly asked about whether John smokes, 
 which means that the QUD is QUD$_\textrm{now}$.
When we use the previous RSA model with the common ground prior, but  
 replace QUD$_\textrm{max}$ with QUD$_\textrm{now}$ (summarized in the 
 last column of Table~\ref{tab:models}), the pragmatic listener's marginal probability over worlds is shown in Figure~\ref{fig:RSA_QUDnow} and the joint
 distribution of world and common ground is in Figure~\ref{fig:joint-QUDnow}.
We can see that $(\verb+#t+, \verb+#t+)$ with common ground \verb=+past= is 
 the only most likely outcome, and the world $(\verb+#t+, \verb+#t+)$ is the 
 single most likely world (and its probability increases with a higher $\alpha$).
This is exactly the projection pattern we aim to capture.

To understand why we obtain this result, we note that 
 when the QUD is QUD$_\textrm{now}$, $(\verb+#f+, \verb+#f+)$ with common ground
 \verb=-now= is dispreferred because the common ground \verb=-now= already entails 
 the answer to the QUD. 
This means that the speaker would be maximally informative even if he says nothing.
As a result, the speaker would be unlikely to say ``John did not stop smoking'' 
 when the common ground is \verb=-now=, and the pragmatic listener could therefore
 infer that the common ground \verb=-now= is unlikely, which means that 
 $(\verb+#t+, \verb+#t+)$ with common ground \verb=+past= is the only winner.

%The model's prediction changes when we use a different QUD. 
%When the QUD is whether John smoked in the past, the model predicts that 
% the listener will infer that world $(\verb+#f+, \verb+#f+)$ with common
% ground \verb=-now= is most likely, as shown in Fig.~\ref{fig:joint-QUDpast}.
%This means that John never smokes and the speaker takes for granted that 
% John does not smoke now.
%This type of projection might be accessible in a scenario where there
% is a rumor about John being a heavy smoker in the past, and the speaker uses 
% ``John did not stop smoking'' to jokingly refute it.

Therefore the current model correctly predicts the projective behavior for 
 ``John did not stop smoking'' in the example scenario, where the QUD is explicitly
 given by Bob's question. 
Assuming that people generally care more about information concerning now than 
 the past, i.e., the default or most salient QUD is QUD$_\text{now}$,
the model predicts that the preferred projective content of 
 ``John did not stop smoking'' without explicit QUD is that 
 John smoked in the past, which is also correct.

This completes the RSA model. In the next section we will further illustrate its predictions about the interaction between projection and QUD. 

